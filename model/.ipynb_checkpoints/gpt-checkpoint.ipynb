{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6b0521-2b32-4539-9c4c-4a864596e707",
   "metadata": {},
   "source": [
    "## **1. Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4e983-f11c-4c58-b547-bb6561fc1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e0b3c-9189-4a0d-9ef1-12a26ff07e88",
   "metadata": {},
   "source": [
    "## **2. Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3ab66-c510-4196-a74f-43e376956659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/tonghop.csv\"\n",
    "df = pd.read_csv(data_path).sample(frac=1, random_state=42)  # Shuffle dataset\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8330241-738e-4034-9b68-f65dfff7db31",
   "metadata": {},
   "source": [
    "## **3. Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48069e-47ef-4294-b4cf-a103a7347a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"sản phẩm\", \"điều khoản\", \"thông tin cửa hàng\", \"khác\"]\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"label\"])\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fbff2c-b4a4-48bf-9566-a6d18e728236",
   "metadata": {},
   "source": [
    "## **4. Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935dc62f-c601-4fdb-9105-f75331243911",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    tokens = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    del tokens[\"token_type_ids\"]  # Bỏ `token_type_ids` để tránh lỗi\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d28544-f342-4123-8850-ce048775cf24",
   "metadata": {},
   "source": [
    "## **5. Create Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b639d-9d1e-4967-82c0-dd920b45230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenize_texts(texts)\n",
    "        self.labels = torch.tensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {key: val[idx] for key, val in self.encodings.items()}, self.labels[idx]\n",
    "\n",
    "train_dataset = IntentDataset(train_texts, train_labels)\n",
    "val_dataset = IntentDataset(val_texts, val_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f3be4-fa7a-40a2-9d3e-eea724b36d21",
   "metadata": {},
   "source": [
    "## **6. Build Transformer Model with MHA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4048e3b-4a9c-4eb2-b48f-fdc9363c8e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=768, num_heads=8)\n",
    "        self.fc = nn.Linear(768, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].unsqueeze(0)\n",
    "        attn_output, _ = self.attention(cls_embedding, cls_embedding, cls_embedding)\n",
    "        output = self.fc(self.dropout(attn_output.squeeze(0)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404adbd-9e3a-4e99-9cca-12de675347be",
   "metadata": {},
   "source": [
    "## **7. Training Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943e878-bc00-4166-b61a-1f147d89a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(labels)\n",
    "model = TransformerClassifier(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0902e265-3e5f-4b61-926e-c6942da9e652",
   "metadata": {},
   "source": [
    "## **8. Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9de638-f813-4b03-b1dc-a9f66b3a7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for batch, labels in train_loader:\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            batch.pop(\"token_type_ids\", None)  # Loại bỏ token_type_ids nếu có\n",
    "            outputs = model(**batch)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            total_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "        print(f\"Epoch {epoch+1}: Loss {total_loss / len(train_loader):.4f}, Acc {total_acc / len(train_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfec6ce-d622-4bdb-ae1b-86cf8790f9bf",
   "metadata": {},
   "source": [
    "## **9. Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4841b-9b76-44c9-a5ea-98f4c323dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename=\"model.pkl\"):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def load_model(filename=\"model.pkl\"):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a6e6f-6968-45b6-8472-9a4ab48d66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model()\n",
    "train_model(model, train_loader, val_loader, epochs=20)\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc87a199-58cf-4b9d-8ce9-6876500229d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model):\n",
    "    model.eval()\n",
    "    inputs = tokenize_texts([text])\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predicted_label = torch.argmax(outputs, dim=1).item()\n",
    "    return label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "# Load model and test prediction\n",
    "model = load_model()\n",
    "print(predict(\"có bán iphone 16 không\", model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
