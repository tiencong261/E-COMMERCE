import faiss
import json
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
from sentence_transformers import CrossEncoder
from flask import Flask, request, jsonify
import google.generativeai as genai
from flask_cors import CORS, cross_origin
import os
from chatbot import load_model, predict, TransformerClassifier

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

app = Flask(__name__)
CORS(app)  # Cho ph√©p CORS ƒë·ªÉ frontend truy c·∫≠p API

# üîπ Load API Key c·ªßa Gemini
genai.configure(api_key="AIzaSyAmLesw2keGhIrZPMEyYJUs1PUqIidIWFU")
model = genai.GenerativeModel("gemini-2.0-flash")
classify_model = load_model("model.pkl")

# üîπ Load d·ªØ li·ªáu s·∫£n ph·∫©m, th√¥ng tin c·ª≠a h√†ng, ƒëi·ªÅu kho·∫£n
with open("data/products.json", "r", encoding="utf-8") as f:
    products = json.load(f)

with open("data/store_info.json", "r", encoding="utf-8") as f:
    intro_info = json.load(f)

with open("data/terms.json", "r", encoding="utf-8") as f:
    terms_info = json.load(f)

# üîπ Kh·ªüi t·∫°o tokenizer v√† model embedding
tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model_emb = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")

def encode_text(text):
    """M√£ h√≥a vƒÉn b·∫£n th√†nh vector embedding s·ª≠ d·ª•ng token [CLS]."""
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    with torch.no_grad():
        output = model_emb(**inputs).last_hidden_state[:, 0, :].cpu().numpy()  # L·∫•y token [CLS]
    return output

# üîπ Ki·ªÉm tra v√† t·∫£i FAISS Index
faiss_index_path = "faiss_index.bin"

if os.path.exists(faiss_index_path):
    index = faiss.read_index(faiss_index_path)
    print("‚úÖ FAISS Index loaded t·ª´ file.")
else:
    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y FAISS Index. ƒêang t·∫°o m·ªõi...")
    product_vectors = np.vstack([
        encode_text(f"{p['name'].lower()} {p['category'].lower()} {p['description'].lower()}")
        for p in products
    ])
    index = faiss.IndexFlatL2(product_vectors.shape[1])
    index.add(product_vectors)
    faiss.write_index(index, faiss_index_path)  # L∆∞u index ƒë·ªÉ s·ª≠ d·ª•ng l·∫°i
    print("‚úÖ FAISS Index ƒë√£ ƒë∆∞·ª£c l∆∞u.")

print(f"üìå FAISS index size: {index.ntotal}")

def rerank_products(query, product_list):
    """S·∫Øp x·∫øp l·∫°i k·∫øt qu·∫£ t√¨m ki·∫øm d·ª±a tr√™n ƒëi·ªÉm s·ªë c·ªßa m√¥ h√¨nh reranker."""
    scores = reranker.predict([(query, p["name"] + " " + p["description"] + " " + p["category"]) for p in product_list])
    sorted_products = [p for _, p in sorted(zip(scores, product_list), reverse=True)]
    return sorted_products[0] if sorted_products else None  # Tr√°nh l·ªói r·ªóng

def search_product(query):
    """T√¨m ki·∫øm s·∫£n ph·∫©m ph√π h·ª£p v·ªõi truy v·∫•n c·ªßa ng∆∞·ªùi d√πng."""
    query_vector = encode_text(query.lower())  # CHUY·ªÇN QUERY TH√ÄNH CH·ªÆ TH∆Ø·ªúNG
    _, top_k = index.search(query_vector, k=5)
    
    if top_k[0][0] == -1:  # N·∫øu kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£
        return None
    
    top_products = [products[i] for i in top_k[0]]
    return rerank_products(query, top_products)

def search_terms(query):
    """T√¨m ƒëi·ªÅu kho·∫£n ph√π h·ª£p v·ªõi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng."""
    query_lower = query.lower()
    for term in terms_info:
        if term["title"].lower() in query_lower:
            return term
    return None

def classify_question(user_input):
    text = user_input
    result = predict(text, classify_model)
    print(result)
    return result

@app.route("/chat", methods=["POST"])
@cross_origin()
def chat():
    """X·ª≠ l√Ω chat t·ª´ ng∆∞·ªùi d√πng."""
    data = request.json
    user_message = data.get("message", "").strip()

    if not user_message:
        return jsonify({"reply": "Vui l√≤ng nh·∫≠p c√¢u h·ªèi!"})

    # üîπ Ph√¢n lo·∫°i c√¢u h·ªèi
    category = classify_question(user_message)

    if category == "s·∫£n ph·∫©m":
        best_match = search_product(user_message)
        if best_match:
            context = f"S·∫£n ph·∫©m li√™n quan: {best_match['name']}, Gi√°: {best_match['price']}, M√¥ t·∫£: {best_match['description']}."
        else:
            context = "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y s·∫£n ph·∫©m ph√π h·ª£p."
    elif category == "th√¥ng tin c·ª≠a h√†ng":
        context = (
            f" **{intro_info['name']}**\n"
            f" ƒê·ªãa ch·ªâ: {intro_info['location']}\n"
            f" Gi·ªù m·ªü c·ª≠a: {intro_info['open_hours']}\n"
            f" Li√™n h·ªá: {intro_info['contact']}\n"
            f" {intro_info['description']}"
        )
    elif category == "ch√†o h·ªèi":
        context = f"Xin ch√†o! üòä {intro_info['description']}"
    elif category == "ƒëi·ªÅu kho·∫£n":
        term = search_terms(user_message)
        if term:
            context = f"üìå **{term['title']}**\n\n{term['content']}"
        else:
            context = "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y ƒëi·ªÅu kho·∫£n ph√π h·ª£p v·ªõi c√¢u h·ªèi c·ªßa b·∫°n."
    else:
        return jsonify({"reply": "Xin l·ªói, c√¢u h·ªèi c·ªßa b·∫°n n·∫±m ngo√†i ph·∫°m vi h·ªó tr·ª£ c·ªßa h·ªá th·ªëng."})

    # üîπ G·ª≠i context v√†o Gemini API
    final_prompt = f"{context}\nC√¢u h·ªèi c·ªßa kh√°ch h√†ng: {user_message}\nTr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán."
    response = model.generate_content(final_prompt)

    return jsonify({"reply": response.text.replace("\n", "<br>")})

if __name__ == "__main__":
    app.run(debug=True)
